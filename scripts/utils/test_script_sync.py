#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Teste da funcionalidade de sincroniza√ß√£o de legendas baseada no roteiro.

Este arquivo testa:
- Sincroniza√ß√£o precisa com roteiro existente
- Elimina√ß√£o da necessidade de transcri√ß√£o
- Integra√ß√£o com o sistema de montagem de v√≠deo
- Compara√ß√£o com m√©todo tradicional
"""

import os
import json
import tempfile
import shutil
import sys
from pathlib import Path

# Adicionar diret√≥rio raiz ao caminho de importa√ß√£o
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from src.core.subtitle_script_sync import ScriptSubtitleSynchronizer, generate_subtitles_from_script
from src.core.subtitle import generate_subtitles_from_script_sync
from src.utils.mock_generator import MockGenerator

def create_test_environment():
    """
    Cria ambiente de teste com arquivos mock.
    """
    import os
    import shutil
    import json
    
    print("üèóÔ∏è Criando ambiente de teste...")
    
    # Criar diret√≥rio tempor√°rio
    test_dir = "test_script_sync_output"
    if os.path.exists(test_dir):
        shutil.rmtree(test_dir)
    os.makedirs(test_dir)
    
    # Criar subdiret√≥rios
    audio_dir = os.path.join(test_dir, "audio")
    subtitles_dir = os.path.join(test_dir, "subtitles")
    os.makedirs(audio_dir)
    os.makedirs(subtitles_dir)
    
    # Criar roteiro de teste
    script_data = {
        "title": "Teste de Sincroniza√ß√£o de Legendas",
        "description": "V√≠deo para testar o novo sistema de sincroniza√ß√£o",
        "language": "pt-BR",
        "scenes": [
            {
                "id": 1,
                "text": "Texto curto."
            },
            {
                "id": 2,
                "text": "Primeira frase. Segunda frase mais longa. Terceira frase final."
            },
            {
                "id": 3,
                "text": "Uma frase muito longa que deveria ser dividida em m√∫ltiplas legendas para melhor legibilidade e compreens√£o do espectador."
            }
        ]
    }
    
    # Salvar roteiro
    script_path = os.path.join(test_dir, "script.json")
    with open(script_path, 'w', encoding='utf-8') as f:
        json.dump(script_data, f, indent=4, ensure_ascii=False)
    
    # Criar arquivos de √°udio mock
    mock_gen = MockGenerator()
    audio_files = []
    
    for i, scene in enumerate(script_data['scenes'], 1):
        audio_file = os.path.join(audio_dir, f"scene_{i}.mp3")
        
        # Simular dura√ß√£o baseada no texto
        text_length = len(scene['text'])
        estimated_duration = max(3.0, text_length / 15.0)  # ~15 chars/second
        
        # Criar arquivo de √°udio mock
        mock_gen.create_mock_audio(audio_file, duration=estimated_duration)
        audio_files.append(audio_file)
        
        print(f"   üìÑ Cena {i}: {estimated_duration:.1f}s - '{scene['text'][:50]}...'")
    
    print(f"‚úÖ Ambiente de teste criado em: {test_dir}")
    print(f"üìÑ Roteiro: {script_path}")
    print(f"üéµ Arquivos de √°udio: {len(audio_files)}")
    
    return test_dir, script_path, audio_files

def test_synchronizer_basic():
    """
    Teste b√°sico do sincronizador.
    """
    print("\nüß™ === TESTE: Sincronizador B√°sico ===")
    
    synchronizer = ScriptSubtitleSynchronizer()
    
    # Teste de c√°lculo de velocidade de fala
    test_text = "Este √© um teste de velocidade de fala para o sistema."
    test_duration = 4.0
    
    speech_rate = synchronizer.calculate_speech_rate(test_text, test_duration)
    print(f"üìä Velocidade calculada: {speech_rate:.1f} chars/s")
    
    # Teste de distribui√ß√£o de timing
    timing_data = synchronizer.distribute_timing_intelligent(
        test_text, test_duration, speech_rate
    )
    
    print(f"üìã Distribui√ß√£o de timing:")
    for i, item in enumerate(timing_data, 1):
        print(f"   {i}. {item['start_time']:.1f}s - {item['end_time']:.1f}s: '{item['text']}'")
    
    # Teste de convers√£o para SRT
    srt_content = synchronizer.generate_srt_from_sync_data(timing_data)
    print(f"\nüìù Conte√∫do SRT gerado:")
    print(srt_content[:200] + "..." if len(srt_content) > 200 else srt_content)
    
    return True

def test_script_sync_integration():
    """
    Teste de integra√ß√£o completa com roteiro.
    """
    print("\nüîó === TESTE: Integra√ß√£o Completa ===")
    
    try:
        # Criar ambiente de teste
        test_dir, script_path, audio_files = create_test_environment()
        
        # Testar sincroniza√ß√£o
        subtitle_file = generate_subtitles_from_script_sync(
            script_path=script_path,
            audio_files=audio_files,
            output_dir=os.path.join(test_dir, "subtitles"),
            style_name="modern"
        )
        
        print(f"‚úÖ Legendas geradas: {subtitle_file}")
        
        # Verificar arquivo gerado
        if os.path.exists(subtitle_file):
            with open(subtitle_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            print(f"üìä Tamanho do arquivo: {len(content)} caracteres")
            print(f"üìÑ N√∫mero de linhas: {len(content.splitlines())}")
            
            # Mostrar primeiras legendas
            lines = content.split('\n')[:15]
            print(f"\nüìù Primeiras legendas:")
            print('\n'.join(lines))
            
            return True
        else:
            print(f"‚ùå Arquivo de legenda n√£o foi criado")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro no teste de integra√ß√£o: {e}")
        return False

def test_timing_accuracy():
    """
    Teste de precis√£o do timing.
    """
    print("\n‚è±Ô∏è === TESTE: Precis√£o do Timing ===")
    
    synchronizer = ScriptSubtitleSynchronizer()
    
    # Cen√°rios de teste
    test_cases = [
        {
            "text": "Texto curto.",
            "duration": 2.0,
            "expected_subtitles": 1
        },
        {
            "text": "Primeira frase. Segunda frase mais longa. Terceira frase final.",
            "duration": 8.0,
            "expected_subtitles": 3
        },
        {
            "text": "Uma frase muito longa que deveria ser dividida em m√∫ltiplas legendas para melhor legibilidade e compreens√£o do espectador.",
            "duration": 10.0,
            "expected_subtitles": 1  # Ser√° uma legenda longa
        }
    ]
    
    all_passed = True
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nüìã Caso de teste {i}:")
        print(f"   Texto: '{case['text']}'")
        print(f"   Dura√ß√£o: {case['duration']}s")
        
        speech_rate = synchronizer.calculate_speech_rate(case['text'], case['duration'])
        timing_data = synchronizer.distribute_timing_intelligent(
            case['text'], case['duration'], speech_rate
        )
        
        print(f"   Legendas geradas: {len(timing_data)}")
        print(f"   Esperado: {case['expected_subtitles']}")
        
        # Verificar timing
        total_time = max(item['end_time'] for item in timing_data) if timing_data else 0
        time_diff = abs(total_time - case['duration'])
        
        print(f"   Tempo total: {total_time:.1f}s (diferen√ßa: {time_diff:.1f}s)")
        
        if time_diff > 0.5:  # Toler√¢ncia de 0.5s
            print(f"   ‚ö†Ô∏è Diferen√ßa de timing muito grande")
            all_passed = False
        else:
            print(f"   ‚úÖ Timing dentro da toler√¢ncia")
    
    return all_passed

def test_performance_comparison():
    """
    Teste de compara√ß√£o de performance.
    """
    print("\nüèÉ === TESTE: Compara√ß√£o de Performance ===")
    
    # Importar m√≥dulos necess√°rios no in√≠cio da fun√ß√£o
    import time
    import os
    import sys
    import json
    import shutil
    
    # Adicionar diret√≥rio raiz ao path para imports
    root_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
    if root_path not in sys.path:
        sys.path.append(root_path)
    
    from src.core.subtitle import generate_subtitles_from_script_sync
    
    # Criar dados de teste
    test_dir, script_path, audio_files = create_test_environment()
    
    print(f"üìä Testando com {len(audio_files)} arquivos de √°udio...")
    
    # Testar m√©todo novo (sincroniza√ß√£o por roteiro)
    start_time = time.time()
    try:
        subtitle_file = generate_subtitles_from_script_sync(
            script_path=script_path,
            audio_files=audio_files,
            output_dir=os.path.join(test_dir, "subtitles_new"),
            style_name="modern"
        )
        new_method_time = time.time() - start_time
        new_method_success = True
        print(f"‚úÖ M√©todo novo: {new_method_time:.2f}s")
    except Exception as e:
        new_method_time = float('inf')
        new_method_success = False
        print(f"‚ùå M√©todo novo falhou: {e}")
    
    # Simular m√©todo tradicional (seria mais lento)
    traditional_time_estimate = len(audio_files) * 30  # 30s por arquivo
    print(f"üìä M√©todo tradicional (estimado): {traditional_time_estimate}s")
    
    if new_method_success:
        speedup = traditional_time_estimate / new_method_time
        print(f"üöÄ Acelera√ß√£o: {speedup:.1f}x mais r√°pido")
        print(f"üí∞ Economia de custo: 100% (sem transcri√ß√£o)")
        return True
    else:
        return False

def test_edge_cases():
    """
    Teste de casos extremos.
    """
    print("\nüîç === TESTE: Casos Extremos ===")
    
    synchronizer = ScriptSubtitleSynchronizer()
    
    edge_cases = [
        {
            "name": "Texto vazio",
            "text": "",
            "duration": 5.0
        },
        {
            "name": "Dura√ß√£o zero",
            "text": "Texto normal",
            "duration": 0.0
        },
        {
            "name": "Texto muito longo",
            "text": "Esta √© uma frase extremamente longa que cont√©m muitas palavras e deveria testar como o sistema lida com textos que excedem a dura√ß√£o normal de uma legenda t√≠pica em v√≠deos.",
            "duration": 3.0
        },
        {
            "name": "Muita pontua√ß√£o",
            "text": "Ol√°! Como vai? Tudo bem... Que bom! At√© logo.",
            "duration": 6.0
        }
    ]
    
    all_passed = True
    
    for case in edge_cases:
        print(f"\nüîç Testando: {case['name']}")
        try:
            speech_rate = synchronizer.calculate_speech_rate(case['text'], case['duration'])
            timing_data = synchronizer.distribute_timing_intelligent(
                case['text'], case['duration'], speech_rate
            )
            print(f"   ‚úÖ Processado: {len(timing_data)} legendas")
        except Exception as e:
            print(f"   ‚ùå Erro: {e}")
            all_passed = False
    
    return all_passed

def run_all_tests():
    """
    Executa todos os testes.
    """
    print("üß™ EXECUTANDO TODOS OS TESTES DE SINCRONIZA√á√ÉO")
    print("=" * 50)
    
    tests = [
        ("Sincronizador B√°sico", test_synchronizer_basic),
        ("Integra√ß√£o Completa", test_script_sync_integration),
        ("Precis√£o do Timing", test_timing_accuracy),
        ("Compara√ß√£o de Performance", test_performance_comparison),
        ("Casos Extremos", test_edge_cases)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
            status = "‚úÖ PASSOU" if result else "‚ùå FALHOU"
            print(f"\n{status}: {test_name}")
        except Exception as e:
            results.append((test_name, False))
            print(f"\n‚ùå ERRO em {test_name}: {e}")
    
    # Resumo final
    print(f"\n{'='*50}")
    print(f"üìä RESUMO DOS TESTES")
    print(f"{'='*50}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ" if result else "‚ùå"
        print(f"   {status} {test_name}")
    
    print(f"\nüéØ RESULTADO FINAL: {passed}/{total} testes passaram")
    
    if passed == total:
        print(f"üéâ TODOS OS TESTES PASSARAM! Sistema pronto para uso.")
    else:
        print(f"‚ö†Ô∏è Alguns testes falharam. Verifique os logs acima.")
    
    return passed == total

def main():
    """
    Fun√ß√£o principal.
    """
    print("üé¨ TESTE DO SISTEMA DE SINCRONIZA√á√ÉO DE LEGENDAS")
    print("Baseado em Roteiro - Sem Transcri√ß√£o")
    print("=" * 60)
    
    try:
        success = run_all_tests()
        
        if success:
            print("\nüöÄ SISTEMA VALIDADO! Pronto para produ√ß√£o.")
            print("\nüí° PR√ìXIMOS PASSOS:")
            print("   1. Teste com seus pr√≥prios arquivos")
            print("   2. Execute: python exemplo_sincronizacao_roteiro.py")
            print("   3. Integre ao seu workflow de produ√ß√£o")
        else:
            print("\nüîß AJUSTES NECESS√ÅRIOS antes do uso em produ√ß√£o.")
            
    except KeyboardInterrupt:
        print("\nüëã Teste interrompido pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå Erro geral: {e}")

if __name__ == "__main__":
    main()